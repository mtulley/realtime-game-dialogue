% -------- Formatting Stuff -------- % 


\documentclass[10pt,twocolumn]{article}
\usepackage{oxycomps}
\usepackage{hyperref}
\newcommand{\fixme}[2][]{#2}
\renewcommand{\fixme}[2][]{\textcolor{red}{#2}}
\bibliography{references}
\pdfinfo{/Title (Large Language Models for Video Game Dialogue)/Author (Max Tulley)}
\title{Large Language Models for Video Game Dialogue}
\author{Max Tulley}
\affiliation{Occidental College}
\email{tulley@oxy.edu}
\begin{document}
\maketitle




% -------- Beginning of Paper Content -------- % 


\begin{abstract}

    This paper examines the use of large language models (LLM) in video game dialogue systems through the design and testing of a top-down role-playing game demo. Based on previous works and literature discussing this topic, this demo game is designed to create a coherent and engaging experience. LLM output is manually evaluated for quality, coherence, and information accuracy. The strategy for generation used in the demo is a system for context management. The goal of this paper is to determine the efficacy of using an LLM for real-time dialogue generation.
    
\end{abstract}

\section{Introduction and Problem Statement}
    
    \par
    Video game dialogue systems have followed broadly similar patterns for decades. As early as the 1980s, games such as Cosmic Soldier experimented with simple branching conversation mechanics that let players choose limited dialogue options. By the 1990s, as computer role-playing games evolved, titles like Fallout expanded these branching systems into more structured dialogue trees and helped popularize the modern CRPG conversation model \cite{barton2008dungeonsanddesktops}. Since then game developers have expanded the size and complexity of dialogue trees including more options for players to choose from, more possible outcomes, and more dialogue overall. For many years this system has been the standard and it seemed like the only viable option for CRPG dialogue. However, despite decades of use, traditional branching dialogue trees remain limited in expressiveness and scalability. Current systems cannot dynamically generate nuanced or context-sensitive conversations, resulting in repetitive player experiences. This paper investigates how LLMs can address these limitations and evaluates their potential impact on player engagement and narrative design.
    
\section{Technical Background}
    
    \par
    Traditional video game dialogue is typically implemented through branching dialogue trees, where designers manually script every possible line and player choice. These systems are easy to control but scale poorly: as the number of branches increases, narrative complexity grows exponentially, making conversations repetitive and difficult to maintain. Because all responses must be authored in advance, dialogue trees struggle to adapt to unpredictable player behavior or provide nuanced, context-sensitive interactions.

    \par
    Recent advances in LLMs offer an alternative approach. Transformer-based models such as GPT and LLaMA generate text by predicting tokens using self-attention, enabling them to produce coherent, flexible dialogue shaped by surrounding context. When paired with techniques like fine-tuning, prompt engineering, and efficient context management, LLMs can be guided to match a game’s narrative style and respond dynamically to player actions. However, they also introduce challenges, including computational cost, unpredictability, and the need for careful control to maintain narrative consistency. Understanding both traditional dialogue systems and modern language model architecture provides the foundation for evaluating LLMs as tools for interactive storytelling.

    \par
    There are several ways to make LLMs perform better at specific tasks. The most basic is providing context. Context is information that the LLM is given inside the prompt which it draws on to generate its response. Context management is the most straightforward strategy to generating domain specific responses. Context management, as defined by \cite{mei2025surveycontextengineeringlarge}, is the ``memory hierarchies, compression techniques, and
    optimization strategies that enable effective information organization and retrieval.'' Other strategies for knowledge systems include fine-tuning and retrieval augmented generation (RAG), which were not used in the demo, but are be discussed in results and discussion section of this paper. Fine-tuning is the process of training a pretrained model on a small, specific dataset in order to improve its output quality for a specific task often at the cost of general output quality \cite{howard2018universallanguagemodelfinetuning}. RAG is a context management system which employs vector databases to search for the most semantically relevant information and inputs the information into the prompt \cite{lewis2021retrievalaugmentedgenerationknowledgeintensivenlp}. These will be discussed in more detail in later sections. 

\section{Prior Work}

    \par
    This section will review recent academic literature which relates to LLMs in video games. This literature review does not follow a systematic approach, however, the process will be described here. The articles discussed were found using the following search query in multiple online databases: ``("Video games" OR "games") AND ("LLM" OR "Large Language Model")''. The articles were then selected manually, and any articles that did not discuss real-time dialogue generation were disregarded. 

    \subsection{Use Cases}

        \par
        This section will explain the common use cases for LLMs in video games discussed in the academic literature. These include real-time dialogue generation, narrative generation, and procedural game world generation.
    
        \subsubsection{Dialogue Generation}
        
            \par
            This topic is the most relevant for this paper since this project will focus on creating dialogue with LLMs. There are two options for LLM generated dialogue. The LLM can generate dialogue during the game development process which would then be implemented into a fixed dialogue system. The other option is to use the LLM for real-time dialogue that is generated while the game is played. The second option is much more revolutionary than the first as it allows for a completely new way to control game dialogue. Because of this, most recent research in this field examines the real-time generation of LLM dialogue\cite{huang_generating_2024}\cite{akoury_framework_2023}\cite{csepregi_effect_nodate}\cite{cox_conversational_2024}.
    
        \subsubsection{Narrative Generation}
            
            \par
            Narrative generation in video games using large language models focuses on the dynamic creation of plotlines, quests, and story arcs rather than just dialogue. By leveraging their ability to understand and produce coherent long-form text, LLMs can generate entire narrative structures that adapt to player actions and in-game events. This enables a shift away from rigid, pre-scripted storylines toward more fluid, emergent storytelling experiences. Games can present players with procedurally generated plots that still maintain thematic consistency, pacing, and character development. LLM-driven narrative generation holds the potential to greatly enhance player agency and replayability, but it also introduces challenges in ensuring narrative coherence, balancing player freedom with plot structure, and integrating generated content with game mechanics and world-building \cite{pcgbook}.
            
        \subsubsection{Procedural Generation}      

            \par
            Procedural generation in video games using large language models enables the creation of rich, varied game content such as quests, lore, item descriptions, and environmental storytelling elements in real time. Unlike traditional procedural systems that rely on handcrafted rules and templates, LLMs can generate content with greater linguistic diversity and contextual awareness, resulting in more immersive and believable worlds. For example, an LLM can create a unique backstory for a village, generate side quests that reference recent player actions, or describe ancient ruins with tone and style consistent with the game’s setting. This allows for high variability without sacrificing narrative depth. However, challenges include maintaining internal consistency, avoiding repetition or contradictions, and ensuring that generated content aligns with game design goals and player expectations \cite{pcgbook}.

    \subsection{Types of Games}

        \par
        This section will evaluate the types of games that previous articles have written about. Some common themes among these papers are the focus on role-playing games and virtual/extended reality. 

        \subsubsection{Role-Playing Games}

            \par
            One of the most frequently mentioned genres of video games in video game LLM papers are role-playing games (RPGs). There is some debate over the definition of role-playing game, like whether the player-character must be a blank slate, but this paper will use the following definition. Role-playing games are games in which the player chooses player attributes such as skills, stats, appearance, and personality. The player's attributes and choices will affect the gameplay and narrative of the game. This genre of video game would benefit massively from the successful integration of LLMs since much of the gameplay of RPGs is dialogue. CRPGs (Computer RPGs) originate from TTRPGs (Table-top RPGs) like Dungeons and Dragons in which the Dungeon Master acts as the NPCs. This allows for incredible emergent gameplay and dynamic NPC-player interaction, since the NPC dialogue is improvised and acted on by a person. CRPGs lack this dynamic and unpredictable NPC interaction. LLMs could potentially add an AI dungeon master to CRPGS and simulate the randomness and unpredictability of real conversation. CRPGs mostly use scripted dialogue which is less interactive than real conversation, since there are only a few dialogue options for the player to choose and a few responses that the NPC can give. Comparing this with an LLM operated NPC where the player can say anything and the NPC can give real-time responses. Clearly an LLM NPC would be much more interactive in a game and simulate real life conversation more accurately. This would make the game world more believable and give the player the feeling of having more control over their character and their conversations with NPCs \cite{christiansen_exploring_2024}.
            
        \subsubsection{Extended Reality}

            \par
            Extended reality is an umbrella term which covers virtual reality, augmented reality, and mixed reality. It is a topic which comes up frequently in the academic research of LLMs in games and for good reason. The goal of implementing LLM-NPCs is to create a more immersive and lifelike world\cite{christiansen_exploring_2024}. This complements extended reality as it too seeks to increase player immersion in the game/media world. Many studies use text-to-speech and speech-to-text for their dialogue systems. This simulates reality better than typing dialogue into a textbox or choosing dialogue from dialogue options. Text-to-speech offers the ability for LLM dialogue to be spoken by an AI voice, so that the NPC can talk to the player. This paper suggests that using text-to-speech actually harms player immersion since AI-voices often fall into the uncanny valley and players can immediately identify an AI generated voice line. Additionally, many studies have identified the delay of LLM response generation to be a technical problem with LLM integration in games. This causes a problem in extended reality games since players are expecting NPCs to act more life-like. In non-extended reality games, say for example a game with text boxes for dialogue, the delay is not as much of a problem since the player will not be expecting lifelike speech behavior from NPCs. The problem of LLM response time can also be mitigated with rolling text, so that the response is given to the player as the LLM is generating it, much like Chat-GPT 4 does.

    

\section{Methods}

    \par
    The method of context engineering used for the demo is context management (refer to the technical background section for definition). The LLM system generates a prompt to send to GPT-4. The prompt is generated with relevant context and instructions that allow the LLM to generate accurate and quality dialogue. Rather than fine-tuning, all task knowledge is supplied at inference time through carefully selected memories, game-state descriptions, and high-level behavioral rules, in line with recent work that frames LLM applications as context-engineered systems \cite{mei2025surveycontextengineeringlarge}. Specific context management strategies for each feature are described in this section, and together they constitute a lightweight but extensible design pattern for LLM-driven NPCs.

    \subsection{NPC Information}
    NPC information consists of name, age, short biography, and personality description. NPC information is retrieved based on the NPC you are speaking to. This allows the LLM system to generate responses which draw on the NPC's personal information and maintain consistent characterization over time. In practice, these fields act as a compact ``character sheet'' that constrains the tone, knowledge, and goals of each NPC. Previous work on LLM-based NPCs has shown that explicitly encoding stable attributes and backstory improves perceived coherence and character consistency, compared with relying on generic prompts alone \cite{huang_generating_2024}. The demo follows this approach by treating NPC information as a persistent, high-priority context block that is always included in the prompt.

    \subsection{Inventory}
    The inventory feature allows the LLM system to know information about the NPCs inventory and the player's inventory. If a player asks about the NPCs inventory, the NPC will be able to answer accurately based on what is actually in their inventory in-game. The items and the amounts of the items are input into the prompt. In addition to answering direct questions (e.g., whether an NPC can sell a particular item), this inventory context enables the LLM to justify refusals, negotiate trades, or reference past exchanges in a way that matches the underlying game state. Making inventory state explicit is especially important in games that combine procedural item generation with dynamic narrative, where inconsistencies between text and mechanics can easily break immersion \cite{pcgbook}.

    \subsection{Dialogue History}
    Every conversation is saved to a separate file. Each NPC has a dialogue history dictionary which contains all previous conversations. When generating the prompt, the previous 20 back and forths from the dialogue history are included. This sliding window acts as a short-term memory that lets the NPC reference recent events, recall player preferences, and maintain conversational threads. Because context windows are finite, the system must balance recency and relevance, a trade-off that is central to context engineering for LLM applications \cite{mei2025surveycontextengineeringlarge}. Similar memory-window strategies are used in other LLM-NPC frameworks and have been shown to improve perceived presence and continuity without incurring prohibitive prompt length \cite{christiansen_exploring_2024}.

    \subsection{Lore}
    The lore feature refers to the LLM system's understanding of the game world lore. Lore includes any factual information about the fictional world. The demo's lore system is limited to a simple paragraph which describes the general lore of the world. Even this short description provides essential grounding, such as factions, geography, and high-level history, which helps the model avoid obviously out-of-world references. In larger games, this lore component could be replaced or augmented by a structured knowledge base or a RAG pipeline that retrieves relevant world facts on demand \cite{lewis2021retrievalaugmentedgenerationknowledgeintensivenlp}. Designing a scalable lore representation is therefore an important direction for future work.

    \subsection{Quests}
    Most CRPGs use quests to further the story and provide the player with tasks to complete. Often, these quests are initiated by speaking to an NPC who assigns a quest to the player. The LLM system, therefore, must be given a list of assignable quests which it can choose to assign to the player at will. The quest system in the demo also includes lists of active and completed quests. Each NPC has its own set of quests that it can assign. Not only do NPC often assign quests, but often times quest objectives (smaller tasks which are part of the larger quest) are completed by speaking to NPCs. Thus the LLM system must know a description of each quest objective so that it can determine what to say to the player regarding quest objectives and when to complete the quest objective. This is contained inside the information of a quest. The LLM is given the quest data and quest state so that it has the proper context to advance quests. The method for quest assignment and objective advancement used in the demo is a tag system. All NPC dialogue is enclosed in quotation marks and tags are enclosed in square brackets. For example, when the LLM system assigns a quest it appends [quest\_assigned, quest\_id] to its output. Similarly for objective advancement it appends [next\_objective, quest\_id]. These tags are then extracted and used to alter the game state.

    \subsection{Directions}
    The directions feature consists of all information that is required for the LLM system to generate accurate descriptions of locational information. The most basic information in this feature is the current location where the conversation is occurring. More complex information can be included depending on the desired functionality of the LLM system. If the game developer wants the LLM system to be able to give accurate directions to a location, then the LLM system needs some textual representation of a map of the game world. The complexity of this map and textual representation will vary between games. For example, a 2D platformer's map will be less complex than an open world RPG. The demo does not include a fully-fledged directions system, but the LLM system sometimes can ascertain correct information from other sources, like NPC bios. Full implementation of a directions system is discussed in the results and discussion section. Other prototypes that ground LLM-NPCs in spatial information suggest that explicit, structured map descriptions or path abstractions are needed for reliable navigation-related dialogue \cite{pcgbook}.

    \subsection{Situation}
    The situation refers to anything immediately surrounding the location of the conversation, which the NPC would be aware of. Situational information consists of time of day, weather, nearby characters, location, and nearby items. Of course, situational information can be expanded or reduced based on the information which the game designer deems relevant. For an NPC in Skyrim, the situation might include the race of each character present and for an NPC in Stardew Valley, the situation might include the current season. Rich situational grounding has been identified as a key factor in creating a feeling of ``presence'' when interacting with LLM-driven agents in simulated worlds and extended reality \cite{christiansen_exploring_2024}. In the demo, this feature is intentionally minimal to keep the prompt size small; the evaluation results highlight the limitations of this design choice.

    \subsection{Items}
    The items feature consists of all information about in-game items that is relevant to the conversation. In standard CRPGs and the demo, this reduces to item descriptions (so the LLM system knows some information about the items) and an item exchange log (so the LLM system knows when items have been exchanged between the player and the NPC). Together with the inventory feature, this allows the NPC to reference specific items, explain their function, and acknowledge trades that happened earlier in the playthrough. Item-centric narrative content and item-based quest hooks are a common focus of procedural content generation and recent LLM-based quest generation systems, making this a natural point of integration between authored game mechanics and generative dialogue \cite{pcgbook}.


\section{Evaluation}

    \par
    In order to test whether an LLM system can generate quality, relevant, real-time dialogue in a video game, a game demo was made. The game demo consists of a small world in which there are several NPCs. The player can talk to the NPCs and complete a quest for one of them. The LLM system was tested for its output for several features. A feature of the LLM system is a specific task that it can perform accurately. The set of features this project was tested on is: directions, NPC information, situation, items, quests, lore, dialogue history, and inventory. These features constitute the majority of the information that a dialogue system would use to generate responses in a CRPG. The high-level implementation of each of these features is explained in the methods section. 
    
    \par
    The LLM system was evaluated on a test suite of questions, following methods presented by authors who advocate structured, scenario-based evaluation for conversational agents \cite{ding2023evaluationframeworkconversationalagents}. The questions were designed to test different capabilities and features of the LLM system. For each feature, a set of inputs and expected outputs were manually written, taking care to test varying complexity of the potential capabilities of the LLM system. Each question was manually evaluated for correct or incorrect answers. The questions were mainly designed to test the LLM system's knowledge and its resilience to hallucinations, rather than subjective qualities such as style or humor. The percentage of questions answered correctly for each feature was used as the evaluation metric. The metric for the overall system is the number of features which scored above 0.5 divided by the number of total features. This aligns with recent practice in LLM application evaluation, where lightweight but targeted test suites are used to monitor behavior across multiple capabilities.

\section{Results and Discussion}

    \par
    The system performed well for most of the proposed features. The following are the results and discussion for each feature. Accuracy scores are the percentage of test suite questions answered correctly for each feature. Where relevant, results are interpreted in light of previous work on LLM-based NPCs and game content generation.

    \subsection{NPC Information}
    The test suite accuracy for NPC information is 100. This means that the LLM can answer questions about the current NPC it is generating dialogue for. This is a fundamental functionality for the LLM system to be able to generate quality dialogue. High performance on this feature suggests that simple, static persona descriptors are sufficient for capturing character-specific facts, consistent with prior findings that LLMs reliably condition on well-structured character prompts \cite{huang_generating_2024}. Remaining limitations are more about narrative depth than factual correctness.

    \subsection{Inventory}
    The inventory feature scored a test suite accuracy of 100 as well. This means that the LLM can recall the items and number of items for the NPCs inventory and the player's inventory. This indicates that explicit inclusion of inventory state in the prompt is sufficient for answering simple fact-based questions and for acknowledging trades. More complex behaviors, such as dynamically proposing trades or optimizing resource use, were not evaluated in this project but would be a natural extension, especially when combined with procedural item or quest generation \cite{pcgbook}.

    \subsection{Dialogue History}
    The system scored a 66 for dialogue history. This metric requires more explanation to understand its significance. The test suite consists of questions in which a piece of information is given to the NPC and then a certain number of back and forths occur and then the player asks the NPC to recall the information. 5 to 30 back and forths were tested in increments of 5. Past 20 back and forths, the system could not recall the information. This makes sense because that is the limit for the amount of dialogue history inputted into the prompt. In other words, failures are primarily due to context truncation rather than model incapacity. This behavior reflects a broader challenge in LLM applications: designing memory mechanisms that preserve salient information across long interactions without exceeding context limits \cite{mei2025surveycontextengineeringlarge,christiansen_exploring_2024}.

    \subsection{Lore}
    The lore section scored a 66. This means that this feature worked for over half of the possible types of questions that the player could ask. Given that the demo only provides a short paragraph of lore, this result suggests that even minimal world descriptions can ground many interactions, but are insufficient for more detailed or specific questions. In larger games, a richer knowledge representation (for example, RAG over a lore database) would likely be needed to reach high accuracy on lore-heavy queries \cite{lewis2021retrievalaugmentedgenerationknowledgeintensivenlp}.

    \subsection{Quests}
    The quests feature scored a 100 for test suite accuracy. The quest system is fully functional. The tag-based interface between the LLM and the game engine worked reliably: whenever the model emitted a quest-related tag, the game state updated as intended. This result is encouraging because quests combine several kinds of structure (state, prerequisites, and narrative justification), and are known to be a challenging domain for procedural and generative systems \cite{pcgbook}. However, the demo still relies on hand-authored quest data; fully generative quests are left for future work.

    \subsection{Directions}
    The directions feature scored a 40. This means it can answer some basic questions about locational information correctly. Complex questions, such as asking for specific directions from location to location, will not be answered correctly. This is consistent with prior observations that spatial reasoning and route description remain difficult for general-purpose LLMs, especially when the map is only implicitly described. A more structured representation of the game map, or a dedicated navigation module, would likely be needed to improve this score.

    \subsection{Situation}
    The situation feature scored a 0 for test suite accuracy. This means that it did not answer any of the expected questions which a player could ask about the immediate situation of the conversation. In the current implementation, situational information is only weakly represented in the prompt, so the model has little to condition on. Prior work on presence and immersion with LLM-driven agents suggests that richer encoding of environmental state (including other characters, objects, and temporal context) is important for believable behavior \cite{christiansen_exploring_2024}. The poor performance here highlights situational grounding as one of the main gaps in the current system.

    \subsection{Items}
    The items feature scored an 85 on test suite accuracy. This means that the LLM system can understand most of the relevant information about the items in the game. Importantly, this includes the item exchange log which tells the LLM system which items have been exchanged between NPC and player.

    \subsection{Overall Results and Conclusion}
    Overall the system scored a 6/8 for number of features which scored above a 50. Features that depend on static or slowly changing information (NPC information, inventory, quests, and items) perform very well, while features that rely on rich world grounding or long-term situational memory (directions, situation, and, to a lesser extent, lore and dialogue history) are noticeably weaker. This pattern mirrors findings from other LLM-in-games prototypes, where character-centric reasoning tends to be more robust than spatial or systemic reasoning \cite{huang_generating_2024,christiansen_exploring_2024,pcgbook}. The results suggest that context engineering alone is sufficient to make LLMs useful for many aspects of CRPG dialogue, but that more sophisticated memory and world-modeling techniques will be necessary to fully replace traditional scripted systems.

\section{Ethical Considerations}

    \par 
    This section will discuss the ethical implications of using Large Language Models to create video game dialogue. These considerations overlap with broader debates about the deployment of LLMs, but games also introduce domain-specific concerns related to player safety, fairness, and manipulation.

    \subsection{Bias}

        \par
        One major issue with LLMs is the unpredictable nature of their responses. They generate response from massive datasets that are difficult to curate. As a result, some problematic data can be used in the training process and cause unwanted effects such as inappropriate or controversial responses. Similarly, bias can be unknowingly trained into an LLM if the data is poisoned\cite{data_poisoning}. In 2023, the World Association for Artificial Consciousness conducted several studies to locate bias in the most popular LLMs. They tested mainstream models for regional, racial, and age bias using evaluation tools and datasets. These studies conclude that the top LLMs have a low to moderate level of regional bias\cite{duan_ranking_nodate}, a low to moderate level of racial bias\cite{duan_large_nodate}, and a moderate to high level of age bias\cite{yucong_duan_large_2024}. These biases can exacerbate social inequalities when LLMs are used in the wrong situations. For example, job application screenings are being done more and more by LLMs which may have biases. This could cause unintentional discrimination against certain applicants. There are many more applications of LLMs which could be problematic, considering potential biases, like insurance, judicial and legal assistants, customer chat bots, educational chat bots, etc. In games, biased NPC behavior or dialogue may reinforce stereotypes or create hostile experiences for particular groups of players.

    \subsection{Security and Privacy}

        \par 
        There are many security and privacy risks involved with the use of large language models. This paper will not discuss every security threat to LLMs generally, but will address issues specific to LLM generated video game dialogue. The specific threats identified in this paper are inference attacks, prompt injection, and extraction attacks. Inference attacks are attacks that seek to obtain information about LLM training data by inference\cite{model_leeching}. These attacks do not seek to gain training data directly, but use inference to gain secondary information. This type of attack is a concern for this project since an adversary who successfully carries out this attack could gain information about the fine-tuned training datasets and exploit this information for gain within the game. A survey of papers discussing LLM vulnerabilities found that fine-tuning adaptive layers rather than the head of the model reduces the risks of membership inference attacks\cite{llm_security_survey}. This is not much of an issue in single-player games, but for a competitive multiplayer game, the adversary might gain an advantage over other players, creating an unfair gaming experience. A similar issue arises with the threat of prompt injection, which occurs when an adversary provides input to the LLM that generates harmful or unintended responses, such as leakage of sensitive information about other players or about the game\cite{prompt_injection}.

    \subsection{Content Moderation}

        \par 
        Content moderation is an essential step in ensuring a safe gaming environment for players. LLM dialogue is generated dynamically, increasing the risk of harmful, offensive, and inappropriate responses. To mitigate this risk, a combination of careful prompt engineering and rule-based moderation is required. There has been some exploration of the use of LLMs as content moderators themselves. One study found that the median precision was 64\% and the median precision was 83\% for several popular LLMs regarding the moderation of content in online forums\cite{content_moderation}. This is better than nothing, but for full protection against harmful content, it is advisable to implement a rule-based system. It is also important to detect and respond to edge cases such as prompt injection, especially in multiplayer games. In addition, developers must decide how to handle borderline content, what logging is appropriate, and how to communicate moderation policies to players.

    \subsection{Creative Authenticity}

        \par 
        There is much discussion about the integrity of LLM generated content. The issue extends to all fields in which LLM are being used, especially in creative fields. Some people argue that LLMs are inauthentic and simply regurgitate what other people have written. This issue is especially significant in academia\cite{academic_integrity}\cite{academic_integrity2}. While large language models are derivative, meaning they generate responses based on previous data, they offer writers the opportunity to generate massive amounts of essentially filler material. When used in conjunction with human written narrative and storytelling, they can be used to fill in a world so that it feels more real while maintaining the narrative of the human writers. In games, this raises questions about authorship, credit, and how much of a game's narrative can be outsourced to generative systems without undermining the work of human writers and narrative designers.

    \subsection{Player Manipulation}

        \par
        Player manipulation is an ongoing issue in video game design. Certain features of games are designed to manipulate players into continuing to play the game, watching advertisements, and spending money. This can be malicious if the methods become predatory or unfair to the player. One issue that is particularly egregious, yet has not received much legal attention is video game gambling. Many games have adopted a loot-crate monetization model in which players spend real world money for a randomized digital content reward. The House of Lords in the UK states that they do not consider this gambling since there is no option to cash out for real money\cite{loot_boxes}. However, for many games there are third party websites which are used to buy and sell accounts for real money, offering players the ability to cash out. Whether or not there is real money involved, the psychological effects of these systems are something to be considered. This issue is pertinent to LLMs in games since LLMs can be subtly used to persuade players to act differently. Players may be convinced to buy an in game item or play for a bit longer. This use of LLMs can quickly become malicious and harm the user's experience, especially if persuasive techniques are tuned using player data or A/B testing.

    

\section{Replication Instructions}

    \par
    This section serves as a step by step guide to running the game demo. 
    \begin{enumerate}
        \item Clone the GitHub repository linked \href{https://github.com/mtulley/llm-dialogue}{here}
        \item Download Godot version 4. You can choose the GDScript only installation or the GDScript and C\# installation. 
        \item Open Godot and import the project folder as a new project. 
        \item Open the project and press the run button in the top right corner of the Godot editor. 
    \end{enumerate}

\section{Code Architecture Overview}
    \par
    The demo code follows standard Godot architecture enforced by the game engine. In order to extend this project, the specific backend implementations of each feature must be understood. For a developer familiar with Godot and RPG game making in Godot, studying the main scene tree should be sufficient to gain a basic understanding of the architecture. There are two ways which context is generated. Either, the context lives in resources that are attached to NPCs, or the context is managed by global scripts. All standard CRPG features are implemented in the standard way for Godot, which would take too long to explain here. Instead, an overview of the main prompt-generating script will be discussed. The dialogue\_ui.gd script contains the compilation function for the prompt. This is the most fundamental script of the program that a developer familiar with Godot and RPG game making in Godot should look at. Read the send\_to\_chatgpt function to understand the order and organization of the prompt. Then, run the demo and speak with an NPC. The entire prompt will be printed to the output tab in the editor. Read one full prompt to understand its components and structure.
    
\printbibliography

\end{document}
